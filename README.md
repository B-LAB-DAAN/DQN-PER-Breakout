# DQN-PER-Breakout: Deep Q-Network с Приоритизированным Буфером Опыта

## Обзор Проекта
Этот проект реализует алгоритм **Deep Q-Network (DQN)** с усовершенствованием **Prioritized Experience Replay (PER)** для обучения агента играть в классическую аркадную игру **Atari Breakout** (`ALE/Breakout-v5`) из библиотеки `Gym`.

Цель проекта — продемонстрировать глубокое понимание алгоритмов Reinforcement Learning и способность к низкоуровневой реализации ключевых компонентов, включая сложную структуру данных для PER, без использования высокоуровневых библиотек RL (таких как Stable Baselines или Keras-RL).

## Ключевые Результаты

* **Достигнутый максимальный Total Reward:** **45.0** (значительное улучшение по сравнению с случайным агентом).
* **Фреймворк:** **PyTorch** для построения нейронной сети и обучения.
* **Реализация PER:** Кастомная реализация структуры данных **SumTree** для эффективного выборки по приоритету.

## Архитектура и Технологии

### 1. Алгоритм
Используется классическая архитектура **DQN** с двумя сетями (Policy Network и Target Network), а также критически важный компонент **Prioritized Experience Replay (PER)**, который позволяет агенту уделять больше внимания "удивительным" (с высоким TD-ошибкой) переходам.

### 2. Нейронная Сеть
Используется **Convolutional Neural Network (CNN)** для обработки входных изображений:

| Слой | Тип | Размер ядра (Kernel) | Шаг (Stride) | Выходной размер |
| :--- | :--- | :--- | :--- | :--- |
| **Conv1** | Conv2d | 8x8 | 4 | 84x84 -> 20x20 |
| **Conv2** | Conv2d | 4x4 | 2 | 20x20 -> 9x9 |
| **Conv3** | Conv2d | 3x3 | 1 | 9x9 -> 7x7 |
| **FC** | Linear | - | - | Выход = 4 действия |

### 3. Гиперпараметры (Основные)

| Параметр | Значение | Описание |
| :--- | :--- | :--- |
| `GAMMA` | `0.99` | Коэффициент дисконтирования. |
| `LR` | `2.5e-4` | Скорость обучения. |
| `BATCH_SIZE` | `64` | Размер батча для обучения. |
| `FRAME_SKIP` | `4` | Выполняет выбранное действие 4 раза для ускорения обучения (в соответствии с рекомендациями DQN). |
| `REPLAY_BUFFER_SIZE` | `200,000` | Максимальный размер буфера. |
| `TARGET_UPDATE` | `100` | Частота обновления весов Target Network (каждые 100 эпизодов). |

## Запуск Проекта

### Требования
Для запуска проекта необходимы следующие библиотеки:

```bash
pip install torch numpy gym opencv-python matplotlib
